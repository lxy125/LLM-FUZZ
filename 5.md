# <span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(238, 249, 253)">8. 文献处理分析：Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries</span></span>

|                                                                                                                                                                                                                                               |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Author:</span></span>**<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)"> ;</span></span>                     |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Journal: (Publication Date: )</span></span>**                                                                                                       |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Journal Tags:</span></span>**                                                                                                                       |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Local Link:</span></span>**                                                                                                                         |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">URL:</span></span>**                                                                                                                                |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Abstract:</span></span>**                                                                                                                           |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Note Date: </span></span>**<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">2024/8/16 09:05:03</span></span> |

## <span style="color: rgb(224, 255, 255)"><span style="background-color: rgb(102, 205, 170)">📜 Research Core</span></span>

***

> Tips: What was done, what problem was solved, innovations and shortcomings?

### ⚙️ Content

利用大型语言模型（LLMs）进行协议模糊测试。该研究主要集中在利用历史漏洞触发代码片段来指导LLMs生成极端情况的程序，从而有效发现深度学习库（如PyTorch和TensorFlow）中的新漏洞。

### 💡 Innovations

**历史漏洞驱动的模糊测试**：FuzzGPT通过历史漏洞触发代码片段来指导LLMs，这是此前研究中未完全自动化或通用化的方法。

**自动化API标注**：研究通过LLMs自动化地将漏洞触发代码与特定API标注相关联，减少了大量手动标注的需求。

**上下文学习与微调**：该研究探讨了两种学习范式——上下文学习和微调，展示了LLMs可以有效适应不同的深度学习库。

### 🧩 Shortcomings

## <span style="color: rgb(32, 178, 170)"><span style="background-color: rgb(175, 238, 238)">🔁 Research Content</span></span>

***

### 💧 Data

使用从深度学习库（如PyTorch和TensorFlow）的GitHub仓库中挖掘的历史漏洞数据集，包括1750个PyTorch和633个TensorFlow的漏洞触发代码片段。

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FIQSZFL5L%22%2C%22pageLabel%22%3A%22842%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B322.303704%2C619.5498288%2C534.8253167999998%2C627.4940592%5D%2C%5B327.918%2C608.5908287999999%2C567.522261824%2C616.5350592%5D%2C%5B317.955%2C597.6318288%2C558.2038598399998%2C605.5760592%5D%2C%5B317.955%2C586.6728287999999%2C405.8960165759998%2C594.6170592%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FRXFZ2763%22%5D%2C%22locator%22%3A%22842%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/IQSZFL5L?page=2">“MT solvers, or any software libraries with accessible APIs). To implement FuzzGPT, we first construct a dataset of bug-triggering code snippets by mining bug reports from open-source repositories of the target DL libraries.”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FRXFZ2763%22%5D%2C%22locator%22%3A%22842%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/RXFZ2763">Deng 等, 2024, p. 842</a></span>)</span>

### 👩🏻‍💻 Method

研究采用了上下文学习（In-context learning）和微调（Fine-tuning）两种方法来训练LLMs，使其能够生成新的漏洞触发程序。其中，上下文学习分为“few-shot”和“zero-shot”两种形式：“few-shot”方法通过提供少量历史漏洞代码示例来指导模型生成新的代码，而“zero-shot”方法则通过给模型提供不完整的历史漏洞代码，要求其完成或修改代码。微调则通过在历史漏洞数据集上对模型进行进一步训练，调整模型参数，使其更加擅长生成类似历史漏洞的代码片段。

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FIQSZFL5L%22%2C%22pageLabel%22%3A%22845%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B154.53819392000005%2C124.3678288%2C294.0471288320001%2C132.3120592%5D%2C%5B53.798%2C113.40882880000001%2C294.0471288319999%2C121.3530592%5D%2C%5B53.798%2C102.4498288%2C294.04712883199994%2C110.3940592%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FRXFZ2763%22%5D%2C%22locator%22%3A%22845%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/IQSZFL5L?page=5">“Specifically, we design three different learning strategies: few-shot, zero-shot, and fine-tune, each uses the annotated bug-triggering code dataset differently to generate”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FRXFZ2763%22%5D%2C%22locator%22%3A%22845%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/RXFZ2763">Deng 等, 2024, p. 845</a></span>)</span>

### 🔬 Experiment

实验部分对FuzzGPT在两个主要的深度学习库——PyTorch和TensorFlow上的表现进行了全面评估。实验结果表明，FuzzGPT显著优于现有的模糊测试工具（如TitanFuzz），在多个关键指标上表现出色。具体来说，FuzzGPT在PyTorch和TensorFlow的最新版本上共检测出了76个漏洞，其中49个已确认是此前未知的漏洞，包括11个高优先级漏洞或安全漏洞。FuzzGPT在代码覆盖率和API覆盖率上也显示出明显的优势，特别是在生成极端情况下的程序方面，展示了LLMs在复杂软件系统中的潜力。

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FIQSZFL5L%22%2C%22pageLabel%22%3A%22841%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B317.955%2C536.3078288%2C559.7130719232001%2C544.2520592000001%5D%2C%5B317.955%2C525.3488288%2C558.2019948288%2C533.2930592%5D%2C%5B317.955%2C514.3898288%2C548.9653295999999%2C522.3340592000001%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FRXFZ2763%22%5D%2C%22locator%22%3A%22841%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/IQSZFL5L?page=1">“shows that FuzzGPT can substantially outperform TitanFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FRXFZ2763%22%5D%2C%22locator%22%3A%22841%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/RXFZ2763">Deng 等, 2024, p. 841</a></span>)</span>

### 📜 Conclusion

研究总结了FuzzGPT在利用历史漏洞数据来引导LLMs生成极端测试程序方面的成功经验。结果表明，FuzzGPT能够在深度学习库的模糊测试中表现出色，发现了多个新漏洞，证明了历史漏洞驱动的方法在提升模糊测试效果方面的有效性。FuzzGPT的成功进一步表明，结合上下文学习和微调的LLMs可以显著增强复杂系统的漏洞检测能力，尤其是在深度学习领域中。

## <span style="color: rgb(0, 77, 153)"><span style="background-color: rgb(135, 206, 250)">🤔 Personal Summary</span></span>

***

> Tips: What aspects did you question, how do you think it can be improved?
>
> 上下文学习分为“**few-shot**”和“**zero-shot**”两种形式：“few-shot”方法通过**提供少量历史漏洞代码示例来指导模型生成新的代码**，而“zero-shot”方法则通过给模型**提供不完整的历史漏洞代码，要求其完成或修改代码。**
>
> **深度学习库**
>
> ### 1. PyTorch
>
> **PyTorch** 是一个由 Facebook's AI Research lab (FAIR) 开发的开源深度学习库，广泛应用于研究和生产环境中。它以其**动态计算图**（Dynamic Computational Graph）而闻名，这使得研究人员能够更灵活地进行模型设计和调试。PyTorch 提供了强大的 **GPU 加速和自动微分机制**，支持各种深度学习任务，如卷积神经网络（CNNs）、循环神经网络（RNNs）和 Transformer 模型。因为其易用性和灵活性，PyTorch 成为许多研究者和开发者的首选工具。
>
> ### 2. TensorFlow
>
> **TensorFlow** 是由 Google Brain 团队开发的另一个广泛使用的开源深度学习库。它最初发布于 2015 年，是一个用于**大规模机器学习**的库，支持多种平台的训练和部署。TensorFlow 提供了静态计算图（Static Computational Graph），允许用户预先定义计算图，并在运行时执行该图。TensorFlow 的强大之处在于其在**生产环境中的部署能力**，尤其是在支持**大规模数据处理和分布式计算**方面。TensorFlow 还拥有丰富的社区支持和大量的扩展工具，如 TensorFlow Lite（移动设备上的深度学习）、TensorFlow Serving（模型部署）等。
>
> **微调**（Fine-tuning）是一个在机器学习特别是深度学习中的常见过程，尤其在使用大型语言模型（LLMs，如 GPT-3、BERT 等）时更为普遍。微调的主要目标是通过在特定任务或领域的较小数据集上进行进一步的训练，使预训练的大型语言模型能够更好地适应该任务或领域的特定需求。
>
> ### 微调的过程：
>
> 1.  **预训练**：
>
>     *   大型语言模型首先在大量通用的文本数据上进行预训练。这些数据通常来自互联网上的各种来源（如书籍、文章、维基百科等）。通过这个过程，模型学习了广泛的语言结构、语法规则、词汇关系以及一定程度上的常识知识。
>     *   预训练阶段通常采用**自监督学习**方法，比如通过**预测句子中的下一个词或填补句子中的空白来学习语言模式**。
>
> 2.  **微调**：
>
>     *   在预训练之后，模型已经掌握了广泛的语言知识，但这些知识是通用的，未必能直接应用于特定任务或领域（如医疗文本分析、法律文档处理等）。
>     *   微调是在一个与目标任务相关的小规模数据集上进一步训练模型。在这个过程中，模型的**权重**会根据特定任务的数据进行调整，从而更好地适应该任务。
>     *   微调通常会使用较小的学习率，因为模型已经经过了大量数据的训练，不需要大幅度调整参数。微调的时间也相对较短，因为模型的基础已经打好。

### 5. 文献处理分析：`Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries`

#### 5.1. 序号 + 文章名称

序号: 8\
文章名称: *Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries*

#### 5.2. 查看是否在GitHub或其他网站存在相应代码

代码存在性: 文中未提到具体的GitHub或其他代码托管平台链接。

#### 5.3. 区分对LLM进行Fuzz还是用LLM辅助Fuzz

该文献使用LLM辅助fuzzing，尤其是生成边缘情况的程序来测试深度学习库。

#### 5.4. 每个fuzz的生成测试样例是什么，对象是什么，和生成策略

*   生成的测试样例: 不常见的DL（深度学习）程序，包含非常规的API组合和参数设置。

*   测试对象: 深度学习库（例如PyTorch和TensorFlow）。

*   生成策略:

    *   **历史漏洞代码片段挖掘**: 使用LLM从开源代码库中挖掘历史漏洞触发代码片段，并利用这些片段指导LLM生成类似的边缘情况程序。
    *   **Few-shot Learning**: 提供几个历史漏洞触发的代码片段作为上下文，指导LLM生成新的程序。
    *   **Zero-shot Learning**: 提供部分或完整的历史代码片段，要求LLM完成代码或编辑代码以生成新程序。
    *   **Fine-tuning**: 对LLM进行微调，使其能够生成类似历史漏洞触发代码的边缘情况程序。//

#### 5.5. 若是Fuzz for LLM，请注明测试的是LLM哪一部分

该文献未涉及对LLM的fuzzing。

#### 5.6. 若是LLM for Fuzz，请注明LLM在Fuzz中发挥了什么作用

LLM在fuzzing中起到了核心作用，通过生成非常规程序来测试深度学习库，以发现潜在的漏洞。

### 总结

本文提出了一种名为FuzzGPT的方法，利用LLM生成边缘情况的程序来进行深度学习库的模糊测试。该方法通过Few-shot、Zero-shot和Fine-tuning等策略，自动生成能够触发潜在漏洞的测试样例。文中没有提到代码是否在GitHub或其他平台上发布。
