# (2024-04-12) Fuzz4All: Universal Fuzzing with Large Language Models

<table><tbody><tr><td style="background-color: rgb(219, 238, 221);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Author:</span></span></strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)"> Chunqiu Steven Xia; Matteo Paltenghi; Jia Le Tian; Michael Pradel; Lingming Zhang;</span></span></p></td></tr><tr><td style="background-color: rgb(243, 250, 244);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Journal: (Publication Date: 2024-04-12)</span></span></strong></p></td></tr><tr><td style="background-color: rgb(219, 238, 221);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Journal Tags:</span></span></strong></p></td></tr><tr><td style="background-color: rgb(243, 250, 244);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Local Link: </span></span></strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)"><a href="zotero://open-pdf/0_2WSGL5KR" rel="noopener noreferrer nofollow">Xia 等 - 2024 - Fuzz4All Universal Fuzzing with Large Language Models.pdf</a></span></span></p></td></tr><tr><td style="background-color: rgb(219, 238, 221);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">DOI: </span></span></strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)"><a href="https://doi.org/10.1145/3597503.3639121" rel="noopener noreferrer nofollow">10.1145/3597503.3639121</a></span></span></p></td></tr><tr><td style="background-color: rgb(243, 250, 244);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Abstract: </span></span></strong><em><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4All, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4All is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language. To realize this potential, we present a novel autoprompting technique, which creates LLM prompts that are wellsuited for fuzzing, and a novel LLM-powered fuzzing loop, which iteratively updates the prompt to create new fuzzing inputs. We evaluate Fuzz4All on nine systems under test that take in six different languages (C, C++, Go, SMT2, Java, and Python) as inputs. The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4All has identified 98 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 64 bugs already confirmed by developers as previously unknown.</span></span></em></p></td></tr><tr><td style="background-color: rgb(219, 238, 221);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Note Date: </span></span></strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">2024/8/15 21:42:47</span></span></p></td></tr></tbody></table>

## 📜 Research Core

* * *

> Tips: What was done, what problem was solved, innovations and shortcomings?

### ⚙️ Content

Fuzz4All是一种新的通用模糊测试工具，利用大型语言模型（LLMs）生成和变异输入，从而能够针对多种不同的输入语言和功能进行模糊测试。该工具通过自动提示生成适合模糊测试的LLM输入提示，并迭代更新提示生成新的模糊测试输入。Fuzz4All在六种不同的编程语言和九个SUT（System Under Test）上进行了测试，显著提高了代码覆盖率，并发现了多个漏洞。

### 💡 Innovations

**Fuzz4All** 的主要创新在于引入了自动提示技术（autoprompting）和利用大型语言模型进行模糊测试。通过这种方式，该工具能够自动生成适合于不同目标系统的输入提示，并通过迭代过程不断改进输入，从而在多种编程语言中实现高效的模糊测试。

“The key idea behind Fuzz4All is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language.” ([Xia 等, 2024, p. 1547](zotero://select/library/items/PF7K4U7J)) ([pdf](zotero://open-pdf/library/items/2WSGL5KR?page=1))

### 🧩 Shortcomings

LLMs 生成的输入在不同语言间的有效性可能有所不同，且生成过程的计算开销较大。此外，某些新兴或特定领域的编程语言或特性可能尚未被LLMs充分学习和理解。

“Since the generation LLM leverages the knowledge acquired during its training done within the last year, reapplying Fuzz4All using the exact checkpoint of the LLM (StarCoder) used in this work might degrade the effectiveness in the future due to data-shift. Fuzz4All can mitigate this using the autoprompting step where more up-to-date documentation/example code allows the model to also generate up-to-date fuzzing inputs.” ([Xia 等, 2024, p. 1557](zotero://select/library/items/PF7K4U7J)) ([pdf](zotero://open-pdf/library/items/2WSGL5KR?page=11))

## 🔁 Research Content

* * *

### 💧 Data

**Fuzz4All** 通过在六种编程语言（如 C、C++、Go、SMT2、Java 和 Python）和九个不同的受测系统（SUTs）上进行测试来验证其有效性。这些系统包括 GCC、Clang、Z3、CVC5、OpenJDK 和 Qiskit 等。

“We perform an extensive evaluation on six input languages (C, C++, SMT, Go, Java, and Python) and nine SUTs. For each of them, we compare our approach against state-of-the-art generationbased and mutation-based fuzzers.” ([Xia 等, 2024, p. 1548](zotero://select/library/items/PF7K4U7J)) ([pdf](zotero://open-pdf/library/items/2WSGL5KR?page=2))

### 👩🏻‍💻 Method

**Fuzz4All** 的方法包括两个主要步骤：自动提示生成（autoprompting）和模糊测试循环（fuzzing loop）。在自动提示生成阶段，该工具从用户输入中提取简明而有效的提示用于模糊测试。在模糊测试循环中，**Fuzz4All** 持续生成和变异输入，通过迭代更新提示来生成新的模糊测试输入。

### 🔬 Experiment

实验部分展示了 **Fuzz4All** 在多个编程语言和受测系统上的性能，并与现有的最先进模糊测试工具进行了比较。实验结果显示，**Fuzz4All** 在所有六种语言中都实现了比现有语言专用模糊测试工具更高的代码覆盖率。此外，**Fuzz4All** 在这些系统中共检测到98个漏洞，其中64个是此前未知的。

“The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4All has identified 98 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 64 bugs already confirmed by developers as previously unknown.” ([Xia 等, 2024, p. 1547](zotero://select/library/items/PF7K4U7J)) ([pdf](zotero://open-pdf/library/items/2WSGL5KR?page=1))

### 📜 Conclusion

研究总结了 **Fuzz4All** 在利用大型语言模型辅助的模糊测试方面的显著优势

## 🤔 Personal Summary

* * *

> - **问题**：在模糊测试中，如何判断LLM生成的输入是否有效，以及如何处理无效的输入？
> - **解答**：输入有效性的标准，例如输入是否符合语法规范、是否能触发目标系统的某些行为等。无效的输入虽然不能直接用于测试，但可以帮助改进提示或揭示LLM在某些情况下的生成缺陷。因此，分析和处理无效输入也是学习的重要部分。
> 
> 判断模糊测试是否成功通常涉及多个方面的考量，包括测试目标的实现程度、测试覆盖率的提高以及漏洞或异常的检测。以下是一些常见的判断标准：
> 
> ### 1\. **代码覆盖率**
> 
> - **解释**：代码覆盖率是衡量测试成功与否的重要指标之一。它表示在测试过程中被执行的代码行或路径的百分比。较高的代码覆盖率通常意味着更多的代码逻辑得到了测试，这增加了发现潜在漏洞的可能性。
> - **判断方法**：可以通过工具（如覆盖率分析工具）测量测试过程中触发的代码覆盖率。如果测试后的覆盖率明显提高，则测试可以被视为成功的一个指标。
> 
> ### 2\. **漏洞检测**
> 
> - **解释**：模糊测试的一个主要目标是发现软件中的漏洞或异常行为。因此，检测到新的漏洞或异常（如崩溃、挂起、内存泄漏等）是成功的标志。
> - **判断方法**：检查模糊测试生成的输入是否导致了目标系统的不期望行为，如崩溃或错误。新发现的漏洞越多，测试越成功。
> 
> ### 3\. **输入有效性**
> 
> - **解释**：测试成功的一个重要方面是生成的测试输入的有效性。有效输入是指能够被目标系统正确处理的输入，而不是被立即拒绝或忽略的输入。
> - **判断方法**：统计生成的测试输入中有多少是有效的，并对无效输入进行分析。如果有效输入占比高且覆盖广泛，测试被认为是成功的。
> 
> ### 4\. **目标功能覆盖**
> 
> - **解释**：成功的模糊测试应能够覆盖并测试目标系统的关键功能或新特性，特别是在进行针对性测试时。
> - **判断方法**：通过分析测试日志或报告，确定是否覆盖了目标系统的所有关键功能。如果所有关键功能都被测试，且未发现明显遗漏，测试可以被视为成功。
> 
> ### 5\. **测试稳定性和重复性**
> 
> - **解释**：成功的测试应当具有稳定性和重复性，即相同的测试在不同时间或环境下重复执行时，应能产生相似的结果。
> - **判断方法**：多次运行同样的模糊测试，观察其结果是否一致。如果结果一致性高，说明测试具有良好的稳定性和可靠性。

### 2\. 文献处理分析：`Fuzz4All: Universal Fuzzing with Large Language Models`

#### 2.1. 序号 + 文章名称

序号: 4  
文章名称: *Fuzz4All: Universal Fuzzing with Large Language Models*

#### 2.2. 查看是否在GitHub或其他网站存在相应代码

代码存在性: 文中未提到具体的GitHub或其他代码托管平台链接。

#### 2.3. 区分对LLM进行Fuzz还是用LLM辅助Fuzz

该文献涉及使用LLM辅助fuzzing。Fuzz4All使用LLM作为输入生成和变异引擎，以生成多种编程语言的输入样例。

#### 2.4. 每个fuzz的生成测试样例是什么，对象是什么，和生成策略

- 生成的测试样例: 多种编程语言的代码片段（包括C、C++、Go、SMT2、Java、Python）。
- 测试对象: 各种系统组件（如编译器、运行时引擎、约束求解器和量子计算平台）。
- 生成策略:
  
    - **Autoprompting**: 自动生成适合fuzzing的LLM提示，并根据用户提供的文档或示例代码生成初始提示。
    - **Fuzzing Loop**: 使用LLM在每次迭代中生成新测试样例，并通过选择示例和生成策略（如生成新的、变异现有的、生成语义等价的代码）来更新提示，生成更多样化的fuzzing输入。
    - **生成引擎**: 使用LLM作为生成引擎来产生多种编程语言的有效代码片段。

#### 2.5. 若是Fuzz for LLM，请注明测试的是LLM哪一部分

该文献未涉及对LLM的fuzzing。

#### 2.6. 若是LLM for Fuzz，请注明LLM在Fuzz中发挥了什么作用

LLM在Fuzz中发挥了关键作用，作为Fuzz4All的输入生成和变异引擎，用于自动生成多种编程语言的输入，并在fuzzing循环中通过选择和生成策略来引导生成新输入。

### 总结

Fuzz4All利用LLM生成和变异多种编程语言的输入样例，以支持通用和定向的fuzzing。文献描述了如何通过autoprompting生成有效的提示，并在fuzzing循环中通过LLM生成新输入样例。文中没有提到代码是否在GitHub或其他平台上发布。