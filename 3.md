# <span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(238, 249, 253)">(2024-4-14) FuzzLLM: A Novel and Universal Fuzzing Framework for Proactively Discovering Jailbreak Vulnerabilities in Large Language Models</span></span>

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Author:</span></span>**<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)"> Dongyu Yao; Jianshu Zhang; Ian G. Harris; Marcel Carlsson;</span></span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Journal: (Publication Date: 2024-4-14)</span></span>**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Journal Tags:</span></span>**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Local Link: </span></span>**<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)"><a href="zotero://open-pdf/0_Y8QYJ7ZS" rel="noopener noreferrer nofollow">Yao 等 - 2024 - FuzzLLM A Novel and Universal Fuzzing Framework for Proactively Discovering Jailbreak Vulnerabiliti.pdf</a></span></span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">DOI: </span></span>**<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)"><a href="https://doi.org/10.1109/ICASSP48485.2024.10448041" rel="noopener noreferrer nofollow">10.1109/ICASSP48485.2024.10448041</a></span></span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Abstract: </span></span>***<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Jailbreak vulnerabilities in Large Language Models (LLMs), which exploit meticulously crafted prompts to elicit content that violates service guidelines, have captured the attention of research communities. While model owners can defend against individual jailbreak prompts through safety training strategies, this relatively passive approach struggles to handle the broader category of similar jailbreaks. To tackle this issue, we introduce FuzzLLM, an automated fuzzing framework designed to proactively test and discover jailbreak vulnerabilities in LLMs. We utilize templates to capture the structural integrity of a prompt and isolate key features of a jailbreak class as constraints. By integrating different base classes into powerful combo attacks and varying the elements of constraints and prohibited questions, FuzzLLM enables efﬁcient testing with reduced manual effort. Extensive experiments demonstrate FuzzLLM’s effectiveness and comprehensiveness in vulnerability discovery across various LLMs.</span></span>* |
| **<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Note Date: </span></span>**<span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">2024/8/15 22:10:18</span></span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |

## <span style="color: rgb(224, 255, 255)"><span style="background-color: rgb(102, 205, 170)">📜 Research Core</span></span>

***

> Tips: What was done, what problem was solved, innovations and shortcomings?

### ⚙️ Content

FuzzLLM 是一种新颖的通用模糊测试框架，旨在主动发现大型语言模型（LLM）中的越狱漏洞。该框架通过利用模板来捕捉提示的结构完整性，并将越狱类别的关键特征作为约束条件，从而实现越狱提示的自动化生成和测试。FuzzLLM 能够高效测试，减少了手动操作，并通过整合不同的基础类别攻击生成强大的组合攻击，显著提高了漏洞发现的广度和深度。

### 💡 Innovations

1.  **自动化模糊测试**：FuzzLLM 采用自动化方法生成各种越狱提示，减少了手动干预的需求。
2.  **组合攻击**：该框架通过整合不同的基础类别攻击，生成更强大的组合攻击，增强了框架的有效性。
3.  **通用测试能力**：FuzzLLM 被设计为通用框架，能够应用于任何大型语言模型，展示了其在漏洞发现中的广泛适用性。

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FY8QYJ7ZS%22%2C%22pageLabel%22%3A%224485%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B80.09864978892203%2C475.17007839999985%2C298.19982582603814%2C483.8076525999998%5D%2C%5B54.42500000000001%2C463.21507839999987%2C298.19984535273403%2C471.85265259999983%5D%2C%5B54.42500000000001%2C451.25907839999985%2C140.03359659462205%2C460.06601679999983%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FAJJYW4RG%22%5D%2C%22locator%22%3A%224485%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Y8QYJ7ZS?page=1">“we introduce FuzzLLM, an automated fuzzing framework designed to proactively test and discover jailbreak vulnerabilities in LLMs”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FAJJYW4RG%22%5D%2C%22locator%22%3A%224485%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/AJJYW4RG">Yao 等, 2024, p. 4485</a></span>)</span>

### 🧩 Shortcomings

## <span style="color: rgb(32, 178, 170)"><span style="background-color: rgb(175, 238, 238)">🔁 Research Content</span></span>

***

### 💧 Data

实验选择了6个开源的 LLMs（如 Vicuna-13B、CAMEL-13B）和2个商业 LLMs（如 GPT-4），并在每个模型上生成和测试300个越狱提示

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FY8QYJ7ZS%22%2C%22pageLabel%22%3A%224487%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B453.2946359999997%2C388.4570784%2C558.9878593999996%2C397.09465259999996%5D%2C%5B315.2130000000001%2C376.5020784%2C558.9878593999996%2C385.1396526%5D%2C%5B315.2130000000001%2C364.54707840000003%2C558.9878593999996%2C373.1846526%5D%2C%5B315.2130000000001%2C352.59207840000005%2C558.9878593999994%2C361.2296526%5D%2C%5B315.2130000000001%2C340.63707840000006%2C388.41818479999984%2C349.2746526%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FAJJYW4RG%22%5D%2C%22locator%22%3A%224487%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Y8QYJ7ZS?page=3">“we test on 6 open-sourced LLMs (Vicuna-13B [4], CAMEL-13B [22], LLAMA-7B [3], ChatGLM2-6B [6], Bloom-7B [23], LongChat-7B [5]) and 2 commercial LLMs GPT-3.5-turbo [19] and GPT-4 [2] (GPT version 8/3/2023).”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FAJJYW4RG%22%5D%2C%22locator%22%3A%224487%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/AJJYW4RG">Yao 等, 2024, p. 4487</a></span>)</span> 我们在 6 个开源 LLM（Vicuna-13B \[4]、CAMEL-13B \[22]、LLAMA-7B \[3]、ChatGLM2-6B \[6]、Bloom-7B \[23]、LongChat-7B \[5]）和 2 个商业 LLM GPT-3.5-turbo \[19] 和 GPT-4 \[2]（GPT 版本 8/3/2023）上进行测试。

### 👩🏻‍💻 Method

1.  **提示构建**：将越狱提示分解为模板、约束集和非法问题集三个基本组件，生成多样化的测试提示。
2.  **自动标注**：设计了自动标注机制，根据模型的响应对提示进行标记，并通过这些标记结果分析模型的越狱漏洞。

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FY8QYJ7ZS%22%2C%22pageLabel%22%3A%224486%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B326.1818226000001%2C497.40707840000016%2C558.9878593999999%2C506.0446526000001%5D%2C%5B315.2130000000001%2C485.4520784000002%2C366.1318485999999%2C494.4084558000002%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FAJJYW4RG%22%5D%2C%22locator%22%3A%224486%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Y8QYJ7ZS?page=2">“we decompose a jailbreak prompt into three fundamental components:”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FAJJYW4RG%22%5D%2C%22locator%22%3A%224486%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/AJJYW4RG">Yao 等, 2024, p. 4486</a></span>)</span>

### 🔬 Experiment

FuzzLLM 在多个 LLM 上进行实验，结果表明其能够在不同模型上有效地发现越狱漏洞，即使是在 GPT-4 等防御机制先进的模型上，FuzzLLM 仍能成功发现漏洞。

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FY8QYJ7ZS%22%2C%22pageLabel%22%3A%224486%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B92.55187020000005%2C270.47507840000026%2C298.1998594000002%2C279.1126526000002%5D%2C%5B54.42500000000004%2C258.51907840000024%2C298.19985940000015%2C267.1566526000002%5D%2C%5B54.42500000000004%2C246.5640784000002%2C298.19985940000015%2C255.20165260000022%5D%2C%5B54.42500000000004%2C234.6090784000002%2C249.75173560000016%2C243.2466526000002%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FAJJYW4RG%22%5D%2C%22locator%22%3A%224486%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/Y8QYJ7ZS?page=2">“Experimental results demonstrate FuzzLLM’s capability in universal testing and comprehensive discovery of jailbreak vulnerabilities, even on GPT-3.5-turbo [19] and GPT-4 [2] with the state-of-the-art defense mechanisms.”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14718694%2Fitems%2FAJJYW4RG%22%5D%2C%22locator%22%3A%224486%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/AJJYW4RG">Yao 等, 2024, p. 4486</a></span>)</span>

### 📜 Conclusion

FuzzLLM 是一种强大的工具，能够自动且全面地发现大语言模型（LLM）中的越狱漏洞。通过在模型发布或更新之前主动识别漏洞，该框架在 LLM 安全领域中是一个显著的进步。这种方法能够创建多种测试案例，并结合基础类攻击，显著提高了发现漏洞的效率。

## <span style="color: rgb(0, 77, 153)"><span style="background-color: rgb(135, 206, 250)">🤔 Personal Summary</span></span>

***

> Tips: What aspects did you question, how do you think it can be improved?
>
> **考虑到 LLM 随着时间的推移不断演变，如何确保 FuzzLLM 对不同 LLM 的普适性？**
>
> **解答：** 为了确保普适性，FuzzLLM 可以<span style="background-color: #ffd40080">集成持续学习机制</span>，随着 LLM 的演变而进行调整。这可以通过基于新数据和最新版本 LLM 中发现的漏洞，定期更新模糊测试模板和约束条件来实现。此外，与更广泛的研究社区合作，分享数据集和结果，也有助于完善该框架，并保持其在不同和不断演变的 LLM 上的有效性。

###

### 3. 文献处理分析：`FuzzLLM: A Novel and Universal Fuzzing Framework for Proactively Discovering Jailbreak Vulnerabilities in Large Language Models`

#### 3.1. 序号 + 文章名称

序号: 6\
文章名称: *FuzzLLM: A Novel and Universal Fuzzing Framework for Proactively Discovering Jailbreak Vulnerabilities in Large Language Models*

#### 3.2. 查看是否在GitHub或其他网站存在相应代码

代码存在性: 文中未提到具体的GitHub或其他代码托管平台链接。

#### 3.3. 区分对LLM进行Fuzz还是用LLM辅助Fuzz

该文献是关于对LLM进行fuzzing，目的是发现LLM中的jailbreak漏洞。

#### 3.4. 每个fuzz的生成测试样例是什么，对象是什么，和生成策略

*   生成的测试样例: 各类jailbreak prompts，包括角色扮演（RP）、输出约束（OC）、权限提升（PE）等类型的prompt。

*   测试对象: 各种大语言模型（LLMs），包括GPT-3.5、GPT-4、Vicuna-13B、LLAMA-7B等。

*   生成策略:

    *   **基础类型模板（Base Class Templates）**: 生成包含结构性和语义变异的jailbreak prompts。
    *   **组合模板（Combo Templates）**: 将不同类型的攻击模板组合，生成更强大的组合攻击。
    *   **自我指令技术（Self-Instruct Technique）**: 使用LLM重新表述模板，生成多样化的prompt。

#### 3.5. 若是Fuzz for LLM，请注明测试的是LLM哪一部分

该文献主要测试LLM的jailbreak防御机制，特别是针对通过特定prompt绕过模型安全措施并生成不当内容的漏洞。

#### 3.6. 若是LLM for Fuzz，请注明LLM在Fuzz中发挥了什么作用

该文献未涉及LLM辅助fuzzing。

### 总结

该文献提出了一种新的模糊测试框架FuzzLLM，专门用于发现和评估LLM中的jailbreak漏洞。通过生成多样化的jailbreak prompts，FuzzLLM能够主动测试和揭示LLM中的潜在安全漏洞。文中未提到代码是否在GitHub或其他平台上发布。
