# (2024-5-20) Training Large Language Models for System-Level Test Program Generation Targeting Non-functional Properties

<table><tbody><tr><td style="background-color: rgb(219, 238, 221);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Author:</span></span></strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)"> Denis Schwachhofer; Peter Domanski; Steffen Becker; Stefan Wagner; Matthias Sauer; Dirk Pflüger; Ilia Polian;</span></span></p></td></tr><tr><td style="background-color: rgb(243, 250, 244);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Journal: (Publication Date: 2024-5-20)</span></span></strong></p></td></tr><tr><td style="background-color: rgb(219, 238, 221);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Journal Tags:</span></span></strong></p></td></tr><tr><td style="background-color: rgb(243, 250, 244);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Local Link: </span></span></strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)"><a href="zotero://open-pdf/0_35UL79XF" rel="noopener noreferrer nofollow">Schwachhofer 等 - 2024 - Training Large Language Models for System-Level Test Program Generation Targeting Non-functional Pro.pdf</a></span></span></p></td></tr><tr><td style="background-color: rgb(219, 238, 221);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">DOI: </span></span></strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)"><a href="https://doi.org/10.1109/ETS61313.2024.10567741" rel="noopener noreferrer nofollow">10.1109/ETS61313.2024.10567741</a></span></span></p></td></tr><tr><td style="background-color: rgb(243, 250, 244);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">Abstract: </span></span></strong><em><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(243, 250, 244)">System-Level Test (SLT) has been an integral part of integrated circuit test flows for over a decade and continues to be significant. Nevertheless, there is a lack of systematic approaches for generating test programs, specifically focusing on the non-functional aspects of the Device under Test (DUT). Currently, test engineers manually create test suites using commercially available software to simulate the end-user environment of the DUT. This process is challenging and laborious and does not assure adequate control over non-functional properties. This paper proposes to use Large Language Models (LLMs) for SLT program generation. We use a pre-trained LLM and fine-tune it to generate test programs that optimize non-functional properties of the DUT, e.g., instructions per cycle. Therefore, we use Gem5, a microarchitectural simulator, in conjunction with Reinforcement Learning-based training. Finally, we write a prompt to generate C code snippets that maximize the instructions per cycle of the given architecture. In addition, we apply hyperparameter optimization to achieve the best possible results in inference.</span></span></em></p></td></tr><tr><td style="background-color: rgb(219, 238, 221);"><p><strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">Note Date: </span></span></strong><span style="color: rgb(25, 60, 71)"><span style="background-color: rgb(219, 238, 221)">2024/8/16 10:20:31</span></span></p></td></tr></tbody></table>

## 📜 Research Core

* * *

> Tips: What was done, what problem was solved, innovations and shortcomings?

### ⚙️ Content

本文提出了一种使用大型语言模型（LLMs）生成系统级测试（SLT）程序的新方法，重点针对被测设备（DUT）的非功能性属性。通过使用预训练的LLM模型并结合强化学习（RL），生成最大化指令每周期（IPC）的C代码片段。该方法在微架构仿真环境中进行训练，以提高SLT程序的生成效果。

### 💡 Innovations

**强化学习驱动的LLM微调**：结合强化学习算法（如近端策略优化PPO）对预训练的LLM进行微调，使其能够生成优化非功能性属性的SLT程序。

“We use a Reinforcement Learning (RL)-based fine-tuning approach to adapt a pre-trained Code Llama to the specific task of SLT program generation.” ([Schwachhofer 等, 2024, p. 2](zotero://select/library/items/R22MNUQM)) ([pdf](zotero://open-pdf/library/items/35UL79XF?page=2))

**微架构仿真反馈**：在微架构仿真环境中，通过仿真反馈对生成的C代码片段进行优化，以提高IPC并探索DUT的非功能性属性。

“we use Gem5, a microarchitectural simulator, in conjunction with Reinforcement Learning-based training.” ([Schwachhofer 等, 2024, p. 1](zotero://select/library/items/R22MNUQM)) ([pdf](zotero://open-pdf/library/items/35UL79XF?page=1))

### 🧩 Shortcomings

**生成代码的多样性和一致性问题**：实验结果表明，使用LLM生成的代码片段在一致性和正确性上存在变异性，某些片段可能无法正确编译或导致仿真崩溃。

“The results of our experiments show two main difficulties: RL-based fine-tuning and the variability in the generated code snippets.” ([Schwachhofer 等, 2024, p. 4](zotero://select/library/items/R22MNUQM)) ([pdf](zotero://open-pdf/library/items/35UL79XF?page=4))

## 🔁 Research Content

* * *

### 💧 Data

使用微架构仿真器Gem5，在超标量、乱序执行的RISC-V处理器上进行仿真。仿真运行1×10^9个时钟周期，对应于模拟的1毫秒。仿真过程中收集IPC等多个指标作为反馈。

“We use Gem5 [11], a microarchitectural simulator, that simulates multiple different ISAs (x86, ARM, RISC-V, and more) and processor architectures.” ([Schwachhofer 等, 2024, p. 2](zotero://select/library/items/R22MNUQM)) ([pdf](zotero://open-pdf/library/items/35UL79XF?page=2))

### 👩🏻‍💻 Method

**强化学习环境**：LLM作为代理，在系统级仿真环境中进行训练，以最大化累计奖励。奖励函数根据代码片段的语法正确性、仿真是否崩溃以及IPC值进行设定。

**提示设计和超参数优化**：在推理过程中，采用贝叶斯优化方法对超参数进行优化，以实现最佳的非功能性指标。输入提示设计也经过优化，以生成高质量的C代码片段。

“A core principle of RL is learning from the interaction of the agent and the environment by applying a trial-and-error approach.” ([Schwachhofer 等, 2024, p. 2](zotero://select/library/items/R22MNUQM)) ([pdf](zotero://open-pdf/library/items/35UL79XF?page=2))

“For Hyperparameter Optimization we use Optuna [15]. It implements the Bayesian optimization method, a Parzen-Tree Estimation-based algorithm.” ([Schwachhofer 等, 2024, p. 2](zotero://select/library/items/R22MNUQM)) ([pdf](zotero://open-pdf/library/items/35UL79XF?page=2))

### 🔬 Experiment

通过100次仿真运行对生成的代码片段进行评估。实验结果表明，微调后的LLM模型在生成能编译且不崩溃的代码片段方面表现更好，且优化后的IPC值更高。

“we generate 100 snippets. For readability of the histogram, we replaced all penalties with 0, such that 0 represents snippets that are not compiling or crashing” ([Schwachhofer 等, 2024, p. 3](zotero://select/library/items/R22MNUQM)) ([pdf](zotero://open-pdf/library/items/35UL79XF?page=3))

### 📜 Conclusion

LLMs在系统级测试程序生成中展现了良好的潜力，尤其在优化非功能性属性方面。但需要进一步改进生成代码的鲁棒性和一致性，未来研究可以考虑将测试工程师纳入生成过程，以利用专家知识进行优化。

## 🤔 Personal Summary

* * *

> Tips: What aspects did you question, how do you think it can be improved?
> 
> 1. **SLT（System-Level Test）**：
>     
>     - **系统级测试**，是指在集成电路（如系统级芯片，SoC）的测试流程中，通过模拟设备的实际使用环境来验证其功能和性能。这种测试通常在设备的实际运行环境中进行，以确保设备在各种真实场景下的可靠性和稳定性。SLT的目标是发现那些在结构化测试中无法检测到的缺陷。
> 2. **DUT（Device Under Test）**：
>     
>     - **被测设备**，指的是正在进行测试的目标设备或系统。在SLT中，DUT通常是一个集成电路或系统级芯片。测试的目的是检查DUT的功能性和非功能性属性，确保其能够在预期的环境中正常工作。
> 3. **IPC（Instructions Per Cycle）**：
>     
>     - **每周期指令数**，是一个衡量处理器效率的重要指标。它表示处理器在一个时钟周期内能够执行的指令数量。IPC越高，通常意味着处理器的性能越好，能够在更短的时间内完成更多的计算任务。在系统级测试中，优化IPC可以提高被测设备的工作效率和功耗表现。
> 4. **策略**
>     
>     是指代理（agent）在特定状态下选择某一动作的概率分布。策略优化的目标是找到一个策略，使得代理在与环境的交互中获得最大的累积奖励。策略优化的一个常见挑战是，在更新策略时可能会导致策略出现较大的变化，从而导致性能下降或不稳定性。
>     
> 5. **代理（Agent）**
>     
>     是指在环境中执行动作并从中学习的主体。代理通过与环境的交互，逐步优化其行为策略，以实现某个目标或最大化其累积奖励。
>     
> 6. **微架构仿真**
>     
>     是指使用软件工具来模拟处理器的底层硬件行为，包括指令的执行、内存访问、缓存行为等。常见的微架构仿真器如 Gem5，可以精确地模拟各种处理器架构（如 x86, ARM, RISC-V）及其执行特性。
>     
> 7. **仿真反馈**
>     
>     指的是从微架构仿真器中获取的性能数据，这些数据可以包括指令每周期（IPC）、缓存命中率、分支预测准确率等。这些指标可以用来衡量生成的C代码片段在处理器上的执行效率。
>     

### 🙋‍♀️ Key Records

### 📌 To be resolved

### 💭 Thought Inspiration

### 8\. 文献处理分析：`Training Large Language Models for System-Level Test Program Generation Targeting Non-functional Properties`

#### 8.1. 序号 + 文章名称

序号: 11  
文章名称: *Training Large Language Models for System-Level Test Program Generation Targeting Non-functional Properties*

#### 8.2. 查看是否在GitHub或其他网站存在相应代码

代码存在性: 文中未提到具体的GitHub或其他代码托管平台链接。

#### 8.3. 区分对LLM进行Fuzz还是用LLM辅助Fuzz

该文献使用LLM辅助生成系统级测试程序，目标是优化设备非功能性属性，因此是LLM辅助fuzzing。

#### 8.4. 每个fuzz的生成测试样例是什么，对象是什么，和生成策略

- 生成的测试样例: C语言代码片段，目标是最大化指令每周期（IPC）的使用。
- 测试对象: 超标量、乱序处理器架构的系统级测试（SLT）程序。
- 生成策略:
  
    - **强化学习（RL）训练**: 使用Gem5微架构仿真器，通过强化学习调整LLM生成的C代码，使其最大化设备的IPC。
    - **Prompt设计**: 编写Prompt以指导LLM生成符合SLT程序要求的C代码。
    - **超参数优化**: 使用贝叶斯优化方法调整LLM的超参数，以最大化仿真过程中获得的非功能性指标。

#### 8.5. 若是Fuzz for LLM，请注明测试的是LLM哪一部分

该文献未涉及对LLM的fuzzing。

#### 8.6. 若是LLM for Fuzz，请注明LLM在Fuzz中发挥了什么作用

LLM在fuzzing中用于生成系统级测试程序，通过强化学习和超参数优化，提高生成程序的性能和有效性。

### 总结

本文探讨了使用LLM生成系统级测试程序，以优化设备的非功能性属性。通过强化学习和超参数优化，LLM生成的程序能够更好地满足系统级测试的需求。文中未提到代码是否在GitHub或其他平台上发布。